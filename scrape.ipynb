{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper.config import get_driver\n",
    "driver = get_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper.controller import ContentFetcher\n",
    "master = ContentFetcher(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.process_url(\"https://www.nitj.ac.in/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "October 10th, 2017 The 2020-Dec-21 9 dec, 1020 1st January 2020 \n",
    "January 12 2021 jan 6 meeting was 9/2/2024 or 04.04.17 or 9/12/14 \n",
    "may 2020-12-31 be at 01/02/2023 2024-09-06 scheduled on 04.04.17, \n",
    "but we moved it to December 21, 1900.\n",
    "Another date was 1st of May, 2020, and finally, the 9 Dec 2020.\n",
    "You can contact me at user@example.com or support@sub.example.co.in.\n",
    "danish.cs.22@nitj.ac.in and mahajandanish0508@gmail.com, mahajan.danish.code@gmail.com and \n",
    "For more information, email us at \"john.doe\"@company.com or admin@192.168.1.1.\n",
    "Also, reach out to user-name@example.org or info@example.photography.\n",
    "Visit our website at http://example.com or check out our FTP server at ftp://files.example.org.\n",
    "For more https://www.nitj.ac.in details, refer to https://www.example.com/path/to/resource?param1=value1#section1.\n",
    "Also, visit https://192.168.1.1:8080/test or a shortened URL like http://bit.ly/xyz123.\n",
    "Here are some phone numbers:\n",
    "+91 9876543210\n",
    "022-12345678\n",
    "987 654 3210\n",
    "+91 9876543210 ext 1234\n",
    "(022) 9876543210\n",
    "(022)-12345678\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/2/20242 9/2/20245 9 dec, 1020 1st January 2020 9/2/20243 9/2/20246 meeting 9/2/2024 04.04.17 9/12/14 may 2020-12-31 01/02/2023 2024-09-06 schedule 04.04.17 move 9/2/20244 another date 9/2/20240 finally 9/2/20241 contact user@example.com support@sub.example.co.in danish.cs.22@nitj.ac.in mahajandanish0508@gmail.com mahajan.danish.code@gmail.com information email u johndoecompanycom admin@192.16811 also reach user-name@example.org info@example.photography visit website http://example.com check ftp server ftp://files.example.org https://www.nitj.ac.in detail refer https://www.example.com/path/to/resource?param1=value1#section1 also visit https://192.168.1.1:8080/test shortened URL like http://bit.ly/xyz123 phone number 91 9876543210 022-12345678 987 654 3210 91 9876543210 ext 9/2/20247 022 9876543210 02212345678\n"
     ]
    }
   ],
   "source": [
    "from TextPreprocessing.Preprocess_Text import TextProcessor\n",
    "\n",
    "processor = TextProcessor()\n",
    "finalText = processor.process_text(text1)\n",
    "print(finalText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VectorDB.vectordb import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relational Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import json\n",
    "\n",
    "# Connect to MySQL\n",
    "conn = mysql.connector.connect(\n",
    "    host='127.0.0.1', \n",
    "    user='root',\n",
    "    password='your_password',\n",
    "    database='cic'\n",
    ")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('extracted_data.json', 'r') as file:\n",
    "    data_d = json.load(file)\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for section, subsections in data_d.items():\n",
    "    for subsection, items in subsections.items():\n",
    "        for item, content in items.items():\n",
    "            result_tuple = (section, subsection, item)\n",
    "            result_list.append(result_tuple)\n",
    "\n",
    "# SQL statement to insert data into the hierarchy table\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO hierarchy (section, subsection, subsubsection)\n",
    "VALUES (%s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# Iterate over the result_list and insert each tuple into the hierarchy table\n",
    "for result_tuple in result_list:\n",
    "    cursor.execute(insert_query, result_tuple)\n",
    "\n",
    "# Commit the changes to the database\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM hierarchy\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "print(rows) # list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold the new tuples in the format (sid, text, NULL)\n",
    "new_tuples = []\n",
    "\n",
    "with open(\"extracted_preprocessed_data.json\", 'r') as file:\n",
    "    data_d1 = json.load(file)\n",
    "\n",
    "# Extract preprocessed text data and form new tuples\n",
    "for sid, section, subsection, subsubsection in rows:\n",
    "    try:\n",
    "        # Access the text data from the nested dictionary structure\n",
    "        text = data_d1[section][subsection][subsubsection]['text']['text']\n",
    "        new_tuple = (sid, text, None)  # None represents NULL in MySQL\n",
    "        new_tuples.append(new_tuple)\n",
    "    except KeyError:\n",
    "        new_tuples.append((sid, None, None))\n",
    "        print(f\"Data not found for section: {section}, subsection: {subsection}, subsubsection: {subsubsection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query to insert data into text_data table\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO text_data (text_id, text, embedding_id)\n",
    "VALUES (%s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# Insert each new tuple into the text_data table\n",
    "for new_tuple in new_tuples:\n",
    "    cursor.execute(insert_query, new_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the changes to the database\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tuples = []\n",
    "\n",
    "for sid, section, subsection, subsubsection in rows:\n",
    "    try:\n",
    "        for img in data_d1[section][subsection][subsubsection]['images']:\n",
    "                url = img['url']\n",
    "                desc = img['description']\n",
    "                desc_ocr = img['description_ocr']\n",
    "                desc_capt = img['description_caption']\n",
    "                form = img['format']\n",
    "                sib = img['sibling_info']\n",
    "                img_tuple = (sid, url, desc, desc_ocr, desc_capt, form, sib, None)  # None represents NULL in MySQL\n",
    "                img_tuples.append(img_tuple)\n",
    "    except KeyError:\n",
    "        print(f\"Data not found for section: {section}, subsection: {subsection}, subsubsection: {subsubsection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    INSERT INTO images_data (\n",
    "        iid, \n",
    "        image_url, \n",
    "        description, \n",
    "        description_ocr, \n",
    "        description_caption, \n",
    "        format, \n",
    "        sibling_info, \n",
    "        embedding_id\n",
    "    ) \n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query with the data\n",
    "cursor.executemany(query, img_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import faiss\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "dimension = 300  \n",
    "index = faiss.IndexFlatL2(dimension)  \n",
    "\n",
    "cursor.execute(\"SELECT text_id, text FROM text_data\")\n",
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_map = {}\n",
    "\n",
    "def process_text_data(text):\n",
    "    if text is None or text.strip() == \"\":\n",
    "        print(\"Empty or None text found. Using default embedding.\")\n",
    "        return tuple(np.zeros(dimension))\n",
    "    doc = nlp(text)\n",
    "    return tuple(doc.vector) \n",
    "\n",
    "def update_embedding_id_in_db(text_id, embedding_id):\n",
    "    update_query = \"\"\"\n",
    "        UPDATE text_data\n",
    "        SET embedding_id = %s\n",
    "        WHERE text_id = %s\n",
    "    \"\"\"\n",
    "    cursor.execute(update_query, (embedding_id, text_id))\n",
    "    conn.commit()   \n",
    "    print(f\"Updated text_id {text_id} with embedding_id {embedding_id}\")\n",
    "\n",
    "def process_and_store_embeddings(rows):\n",
    "    for row in rows:\n",
    "        text_id, text = row   \n",
    "        \n",
    "        embedding = process_text_data(text)\n",
    "        embedding_id = str(uuid.uuid4())\n",
    "        embedding_map[embedding] = embedding_id\n",
    "\n",
    "\n",
    "        embedding_array = np.expand_dims(np.array(embedding, dtype=\"float32\"), axis=0)\n",
    "        index.add(embedding_array)\n",
    "\n",
    "        update_embedding_id_in_db(text_id, embedding_id)\n",
    "\n",
    "        print(f\"Text ID: {text_id} - Embedding ID: {embedding_id}\")\n",
    "\n",
    "    return list(embedding_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_ids = process_and_store_embeddings(rows)\n",
    "\n",
    "faiss.write_index(index, 'faiss_index.index')\n",
    "print(\"FAISS index has been saved to 'faiss_index.index'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"faiss_index.index\")\n",
    "\n",
    "num_vectors = index.ntotal\n",
    "print(f\"Number of vectors in the index: {num_vectors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedding_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT iid, description, description_ocr, description_caption, sibling_info FROM images_data\")\n",
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    iid, description, description_ocr, description_caption, sibling_info = row\n",
    "\n",
    "    combined_text = \" \".join(\n",
    "        filter(None, [description, description_ocr, description_caption, sibling_info])\n",
    "    ).strip()\n",
    "\n",
    "    if not combined_text:\n",
    "        continue\n",
    "\n",
    "    doc = nlp(combined_text)\n",
    "    embedding = tuple(doc.vector)\n",
    "\n",
    "    if embedding not in embedding_map:\n",
    "        embedding_id = str(uuid.uuid4())  # Create a unique embedding ID\n",
    "        embedding_map[embedding] = embedding_id  # Store in dictionary\n",
    "\n",
    "        embedding_array = np.expand_dims(np.array(embedding, dtype=\"float32\"), axis=0)\n",
    "        index.add(embedding_array)\n",
    "\n",
    "        print(f\"Generated and added new embedding for IID {iid}\")\n",
    "    else:\n",
    "        embedding_id = embedding_map[embedding]\n",
    "        print(f\"Embedding already exists for IID {iid}, reusing ID: {embedding_id}\")\n",
    "\n",
    "        # Update the embedding_id in the images_data table\n",
    "    cursor.execute(\n",
    "       \"UPDATE images_data SET embedding_id = %s WHERE iid = %s\",\n",
    "        (embedding_id, iid)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"faiss_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"faiss_index.index\")\n",
    "\n",
    "num_vectors = index.ntotal\n",
    "print(f\"Number of vectors in the index: {num_vectors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pretrained text generation model from Hugging Face\n",
    "response_generator = pipeline(\"text2text-generation\", model=\"t5-small\")\n",
    "\n",
    "def generate_response(texts):\n",
    "    combined_text = \" \".join(texts)\n",
    "    \n",
    "    # Prepare the input prompt for the model\n",
    "    prompt = f\"Summarize and provide a clear response based on the following information: {combined_text}\"\n",
    "\n",
    "    # Use the language model to generate the response\n",
    "    try:\n",
    "        response = response_generator(prompt, max_length=200, truncation=True)\n",
    "        return response[0]['generated_text']\n",
    "    except Exception as e:\n",
    "        print(f\"Error in response generation: {e}\")\n",
    "        return \"An error occurred while generating the response. Please try again later.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query_and_generate_response(query, k=5):\n",
    "\n",
    "    preprocessed_query = preprocess_text(query)\n",
    "\n",
    "    query_embedding = proc_text_data(preprocessed_query)\n",
    "\n",
    "    D, I = index.search(np.expand_dims(query_embedding, axis=0), k=k) \n",
    "\n",
    "    embedding_ids = []\n",
    "\n",
    "    for idx in I[0]:   \n",
    "       idx = int(idx)\n",
    "       retrieved_embedding = index.reconstruct(idx)\n",
    "       retrieved_embedding_tuple = tuple(retrieved_embedding)\n",
    "       embedding_id = embedding_map.get(retrieved_embedding_tuple)\n",
    "       if embedding_id:\n",
    "           embedding_ids.append(embedding_id)\n",
    "\n",
    "    texts = []\n",
    "    if embedding_ids:\n",
    "        texts = fetch_texts_from_database(embedding_ids)\n",
    "\n",
    "    if texts:\n",
    "        response = generate_response(texts)\n",
    "        return response\n",
    "    else:\n",
    "        return \"Sorry, I couldn't find relevant information for your query.\"\n",
    "\n",
    "def proc_text_data(text):\n",
    "\n",
    "    if text is None or text.strip() == \"\":\n",
    "        print(\"Empty or None text found. Using default embedding.\")\n",
    "        return np.zeros(dimension)\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    return doc.vector  \n",
    "\n",
    "def fetch_texts_from_database(embedding_ids):\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT text FROM text_data WHERE embedding_id IN (%s)\n",
    "    \"\"\" % ','.join(['%s'] * len(embedding_ids))   \n",
    "    cursor.execute(query, tuple(embedding_ids))\n",
    "    results = cursor.fetchall()\n",
    "    \n",
    "    texts = [result[0] for result in results]  \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When was NIT Jalandhar established\"\n",
    "response = process_query_and_generate_response(query, k=3)  # Fetch top 3 closest embeddings\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
